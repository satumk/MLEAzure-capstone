{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1611839860542
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "from train import clean_data\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
    "\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1611840576803
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-136380\n",
      "Azure region: southcentralus\n",
      "Subscription id: 2c48c51c-bd47-40d4-abbe-fb8eabd19c8c\n",
      "Resource group: aml-quickstarts-136380\n",
      "Creating\n",
      "Succeeded................................................................................................................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Wait timeout has been reached\n",
      "Current provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws.write_config(path='.azureml')\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'Titanic_project'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = experiment.start_logging()\n",
    "\n",
    "amlcompute_cluster_name = \"ML-cluster-uda\"\n",
    "\n",
    "try:\n",
    "      compute_target=ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "      print(\"Found existing cluster.Using it\")\n",
    "except ComputeTargetException:\n",
    "      compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", max_nodes=4)\n",
    "      compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output = True, min_node_count=1, timeout_in_minutes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1611841963422
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500  None        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250  None        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500  None        S  \n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "key = \"titanic\"\n",
    "description_text = \"Titanic survival classification data from Kaggle\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        data = ws.datasets[key] \n",
    "else :\n",
    "    data = pd.read_csv(\"./titanic.csv\")\n",
    "\n",
    "x, y = clean_data(data.to_pandas_dataframe())\n",
    "x['y']=y\n",
    "print(x.head(5))\n",
    "print(x.describe())\n",
    "x = Dataset.Tabular.from_delimited_files(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'int' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-93d634671040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                              \u001b[0mdebug_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"automl_errors.log\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                              \u001b[0mn_cross_validations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                              \u001b[0;34m**\u001b[0m\u001b[0mautoml_settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                             )\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for ** or pow(): 'int' and 'dict'"
     ]
    }
   ],
   "source": [
    "# TODO: Put your automl settings here\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=df,\n",
    "                             label_column_name=\"y\",   \n",
    "                             path = \"./\",\n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             n_cross_validations=5,\n",
    "                             **automl_settings\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Submit your experiment\n",
    "ds = ws.get_default_datastore()\n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=metrics_output_name,\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='model_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=best_model_output_name,\n",
    "                           training_output=TrainingOutput(type='Model'))\n",
    "\n",
    "automl_step = AutoMLStep(\n",
    "    name='automl_module',\n",
    "    automl_config=automl_config,\n",
    "    outputs=[metrics_data, model_data],\n",
    "    allow_reuse=True)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    description=\"pipeline_with_automlstep\",\n",
    "    workspace=ws,    \n",
    "    steps=[automl_step])\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# save the best model\n",
    "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "num_file_downloaded = best_model_output.download('.', show_progress=True)\n",
    "\n",
    "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
    "    best_model = pickle.load(f)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run_auto.register_model(model_name = 'automl_best_model.pkl', model_path='outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"Titanic_survival\", description=\"Titanic Survival pipeline\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# URL for the web service:\n",
    "scoring_uri = ''\n",
    "# If the service is authenticated, set the key or token\n",
    "key = ''\n",
    "\n",
    "# Two sets of data to score, so we get two results back\n",
    "data = {\"data\":\n",
    "        [\n",
    "          {\n",
    "            \"age\": 17,\n",
    "            \"campaign\": 1,\n",
    "            \"cons.conf.idx\": -46.2,\n",
    "            \"cons.price.idx\": 92.893,\n",
    "            \"contact\": \"cellular\",\n",
    "            \"day_of_week\": \"mon\",\n",
    "            \"default\": \"no\",\n",
    "            \"duration\": 971,\n",
    "            \"education\": \"university.degree\",\n",
    "            \"emp.var.rate\": -1.8,\n",
    "            \"euribor3m\": 1.299,\n",
    "            \"housing\": \"yes\",\n",
    "            \"job\": \"blue-collar\",\n",
    "            \"loan\": \"yes\",\n",
    "            \"marital\": \"married\",\n",
    "            \"month\": \"may\",\n",
    "            \"nr.employed\": 5099.1,\n",
    "            \"pdays\": 999,\n",
    "            \"poutcome\": \"failure\",\n",
    "            \"previous\": 1\n",
    "          },\n",
    "          {\n",
    "            \"age\": 87,\n",
    "            \"campaign\": 1,\n",
    "            \"cons.conf.idx\": -46.2,\n",
    "            \"cons.price.idx\": 92.893,\n",
    "            \"contact\": \"cellular\",\n",
    "            \"day_of_week\": \"mon\",\n",
    "            \"default\": \"no\",\n",
    "            \"duration\": 471,\n",
    "            \"education\": \"university.degree\",\n",
    "            \"emp.var.rate\": -1.8,\n",
    "            \"euribor3m\": 1.299,\n",
    "            \"housing\": \"yes\",\n",
    "            \"job\": \"blue-collar\",\n",
    "            \"loan\": \"yes\",\n",
    "            \"marital\": \"married\",\n",
    "            \"month\": \"may\",\n",
    "            \"nr.employed\": 5099.1,\n",
    "            \"pdays\": 999,\n",
    "            \"poutcome\": \"failure\",\n",
    "            \"previous\": 1\n",
    "          },\n",
    "          {\n",
    "            \"age\": 55,\n",
    "            \"campaign\": 1,\n",
    "            \"cons.conf.idx\": -46.2,\n",
    "            \"cons.price.idx\": 92.893,\n",
    "            \"contact\": \"cellular\",\n",
    "            \"day_of_week\": \"mon\",\n",
    "            \"default\": \"no\",\n",
    "            \"duration\": 471,\n",
    "            \"education\": \"university.degree\",\n",
    "            \"emp.var.rate\": -1.8,\n",
    "            \"euribor3m\": 1.299,\n",
    "            \"housing\": \"yes\",\n",
    "            \"job\": \"blue-collar\",\n",
    "            \"loan\": \"no\",\n",
    "            \"marital\": \"married\",\n",
    "            \"month\": \"may\",\n",
    "            \"nr.employed\": 5099.1,\n",
    "            \"pdays\": 999,\n",
    "            \"poutcome\": \"failure\",\n",
    "            \"previous\": 1\n",
    "          },\n",
    "\n",
    "      ]\n",
    "    }\n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "with open(\"data.json\", \"w\") as _f:\n",
    "    _f.write(input_data)\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Set with the deployment name\n",
    "name = \"titanic-votingensemble\"\n",
    "\n",
    "# load existing web service\n",
    "service = Webservice(name=name, workspace=ws)\n",
    "\n",
    "# enable application insight\n",
    "service.update(enable_app_insights=True)\n",
    "\n",
    "logs = service.get_logs()\n",
    "\n",
    "for line in logs.split('\\n'):\n",
    "    print(line)\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

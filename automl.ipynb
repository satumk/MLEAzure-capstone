{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1612073884844
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "from train import clean_data\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "#pip install pyarrow>=0.12.0 --upgrade\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
    "\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1612073896260
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-136684\n",
      "Azure region: southcentralus\n",
      "Subscription id: 3d1a56d2-7c81-4118-9790-f85d1acf0c77\n",
      "Resource group: aml-quickstarts-136684\n",
      "Found existing cluster.Using it\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws.write_config(path='.azureml')\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'Titanic_project'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = experiment.start_logging()\n",
    "\n",
    "amlcompute_cluster_name = \"ML-cluster-uda\"\n",
    "\n",
    "try:\n",
    "      compute_target=ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "      print(\"Found existing cluster.Using it\")\n",
    "except ComputeTargetException:\n",
    "      compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\", max_nodes=4)\n",
    "      compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output = True, min_node_count=1, timeout_in_minutes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1612074452290
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass  Sex Age  SibSp  Parch     Fare  FamilySize  IsAlone  y\n",
      "0            1       3    0   1      1      0   7.2500           1        0  0\n",
      "1            2       1    1   2      1      0  71.2833           1        0  1\n",
      "2            3       3    1   3      0      0   7.9250           0        1  1\n",
      "3            4       1    1   4      1      0  53.1000           1        0  1\n",
      "4            5       3    0   5      0      0   8.0500           0        1  0\n",
      "       PassengerId      Pclass         Sex       SibSp       Parch  \\\n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean    446.000000    2.308642    0.352413    0.523008    0.381594   \n",
      "std     257.353842    0.836071    0.477990    1.102743    0.806057   \n",
      "min       1.000000    1.000000    0.000000    0.000000    0.000000   \n",
      "25%     223.500000    2.000000    0.000000    0.000000    0.000000   \n",
      "50%     446.000000    3.000000    0.000000    0.000000    0.000000   \n",
      "75%     668.500000    3.000000    1.000000    1.000000    0.000000   \n",
      "max     891.000000    3.000000    1.000000    8.000000    6.000000   \n",
      "\n",
      "             Fare  FamilySize     IsAlone           y  \n",
      "count  891.000000  891.000000  891.000000  891.000000  \n",
      "mean    32.204208    0.904602    0.602694    0.383838  \n",
      "std     49.693429    1.613459    0.489615    0.486592  \n",
      "min      0.000000    0.000000    0.000000    0.000000  \n",
      "25%      7.910400    0.000000    0.000000    0.000000  \n",
      "50%     14.454200    0.000000    1.000000    0.000000  \n",
      "75%     31.000000    1.000000    1.000000    1.000000  \n",
      "max    512.329200   10.000000    1.000000    1.000000  \n",
      "Uploading an estimated of 1 files\n",
      "Uploading data/prepared.csv\n",
      "Uploaded data/prepared.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "key = \"titanic\"\n",
    "description_text = \"Titanic survival classification data from Kaggle\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        data = ws.datasets[key] \n",
    "else :\n",
    "    data = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "x, y = clean_data(data.to_pandas_dataframe())\n",
    "x['y']=y\n",
    "print(x.head(5))\n",
    "print(x.describe())\n",
    "\n",
    "# turning pandas dataframe to Tabular data\n",
    "data_folder = './data'\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "local_path = 'data/prepared.csv'\n",
    "x.to_csv(local_path)\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir='data', target_path='data')\n",
    "\n",
    "dataset = Dataset.Tabular.from_delimited_files(path=[(datastore, ('data/prepared.csv'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and cofiguration you used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1612074464299
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Put your automl settings here\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                             task = \"classification\",\n",
    "                             training_data=dataset,\n",
    "                             label_column_name=\"y\",   \n",
    "                             path = \"./data\",\n",
    "                             enable_early_stopping= True,\n",
    "                             featurization= 'auto',\n",
    "                             debug_log = \"automl_errors.log\",\n",
    "                             n_cross_validations=5,\n",
    "                             **automl_settings\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1612074487587
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step automl_module [e8b3974b][be24f2cd-5e5d-4332-b299-69aa3e66e858], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun b1af25fe-388d-4598-965f-7ef824089048\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/Titanic_project/runs/b1af25fe-388d-4598-965f-7ef824089048?wsid=/subscriptions/3d1a56d2-7c81-4118-9790-f85d1acf0c77/resourcegroups/aml-quickstarts-136684/workspaces/quick-starts-ws-136684\n"
     ]
    }
   ],
   "source": [
    "# TODO: Submit your experiment\n",
    "remote_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1612074513372
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2202f79d88bd47d591cc93ba2a4b64df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/Titanic_project/runs/b1af25fe-388d-4598-965f-7ef824089048?wsid=/subscriptions/3d1a56d2-7c81-4118-9790-f85d1acf0c77/resourcegroups/aml-quickstarts-136684/workspaces/quick-starts-ws-136684\", \"run_id\": \"b1af25fe-388d-4598-965f-7ef824089048\", \"run_properties\": {\"run_id\": \"b1af25fe-388d-4598-965f-7ef824089048\", \"created_utc\": \"2021-01-31T06:28:02.94606Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-01-31T06:57:43.738052Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlstrg136684.blob.core.windows.net/azureml/ExperimentRun/dcid.b1af25fe-388d-4598-965f-7ef824089048/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=U4SCbbv62utbBHa%2BzlVlndrhl25PlY7lhBWt6KZ%2BYts%3D&st=2021-01-31T07%3A19%3A32Z&se=2021-01-31T15%3A29%3A32Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlstrg136684.blob.core.windows.net/azureml/ExperimentRun/dcid.b1af25fe-388d-4598-965f-7ef824089048/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=C%2Fqf3pa%2BC4tveZyMbbnVUv9vgnri3q81st58CSxD4j0%3D&st=2021-01-31T07%3A19%3A32Z&se=2021-01-31T15%3A29%3A32Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlstrg136684.blob.core.windows.net/azureml/ExperimentRun/dcid.b1af25fe-388d-4598-965f-7ef824089048/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=q5sSUjOiNZcAnaMXli3hlmnPp8d2DNHl%2BscErMvKZv4%3D&st=2021-01-31T07%3A19%3A32Z&se=2021-01-31T15%3A29%3A32Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:29:40\"}, \"child_runs\": [{\"run_id\": \"72ca3d3a-66d0-4ee3-92a8-dfe1534d65da\", \"name\": \"automl_module\", \"status\": \"Finished\", \"start_time\": \"2021-01-31T06:28:32.660278Z\", \"created_time\": \"2021-01-31T06:28:14.402209Z\", \"end_time\": \"2021-01-31T06:56:35.768914Z\", \"duration\": \"0:28:21\", \"run_number\": 35, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-31T06:28:14.402209Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-01-31 06:28:14Z] Submitting 1 runs, first five are: e8b3974b:72ca3d3a-66d0-4ee3-92a8-dfe1534d65da\\n[2021-01-31 06:57:39Z] Completing processing run id 72ca3d3a-66d0-4ee3-92a8-dfe1534d65da.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"db273724\": {\"node_id\": \"db273724\", \"name\": \"19dae19b-b57e-4cd2-ba07-801e66516946\"}}, \"module_nodes\": {\"e8b3974b\": {\"node_id\": \"e8b3974b\", \"name\": \"automl_module\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"72ca3d3a-66d0-4ee3-92a8-dfe1534d65da\"}}, \"edges\": [{\"source_node_id\": \"db273724\", \"source_node_name\": \"19dae19b-b57e-4cd2-ba07-801e66516946\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"e8b3974b\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"72ca3d3a-66d0-4ee3-92a8-dfe1534d65da\", \"name\": \"automl_module\", \"status\": \"Finished\", \"start_time\": \"2021-01-31T06:28:32.660278Z\", \"created_time\": \"2021-01-31T06:28:14.402209Z\", \"end_time\": \"2021-01-31T06:56:35.768914Z\", \"duration\": \"0:28:21\", \"run_number\": 35, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-01-31T06:28:14.402209Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.20.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1612076432237
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading azureml/72ca3d3a-66d0-4ee3-92a8-dfe1534d65da/model_data\n",
      "Downloaded azureml/72ca3d3a-66d0-4ee3-92a8-dfe1534d65da/model_data, 1 files out of an estimated total of 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('datatransformer',\n",
       "                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
       "                                 feature_sweeping_config=None,\n",
       "                                 feature_sweeping_timeout=None,\n",
       "                                 featurization_config=None, force_text_dnn=None,\n",
       "                                 is_cross_validation=None,\n",
       "                                 is_onnx_compatible=None, logger=None,\n",
       "                                 observer=None, task=None, working_dir=None)),\n",
       "                ('prefittedsoftvotingclassifier',...\n",
       "                                                                                                    min_samples_split=0.056842105263157895,\n",
       "                                                                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                                                                    n_estimators=50,\n",
       "                                                                                                    n_jobs=1,\n",
       "                                                                                                    oob_score=False,\n",
       "                                                                                                    random_state=None,\n",
       "                                                                                                    verbose=0,\n",
       "                                                                                                    warm_start=False))],\n",
       "                                                                     verbose=False))],\n",
       "                                               flatten_transform=None,\n",
       "                                               weights=[0.16666666666666666,\n",
       "                                                        0.08333333333333333,\n",
       "                                                        0.08333333333333333,\n",
       "                                                        0.08333333333333333,\n",
       "                                                        0.08333333333333333,\n",
       "                                                        0.25,\n",
       "                                                        0.08333333333333333,\n",
       "                                                        0.16666666666666666]))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run_auto, best_model = remote_run.get_output()\n",
    "best_run_auto.get_tags()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = 'Titanic survival AutoML model'\n",
    "model = remote_run.register_model(description = description, tags={'area': 'titanic'}, model_path='outputs/')\n",
    "model_framework=Model.Framework(SCIKITLEARN, model_framework_version='0.19.1') #eka sulje voi olla väärässä paikassa\n",
    "\n",
    "print(run.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                                memory_gb=2,\n",
    "                                                enable_app_insights=True, # standout suggestion\n",
    "                                                auth_enabled=True)  \n",
    "\n",
    "service_name = 'titanic_survival_service'\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], deployment_config=aci_config)\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "\n",
    "print(service.state)\n",
    "print(\"scoring URI: \" + service.scoring_uri)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAIHTOEHTO 2, JOKA EI VIELÄ OIKEIN TOIMI\n",
    "\n",
    "#myenv = Environment.get(workspace=ws, name=\"AzureML-Tutorial\").clone(env_name)\n",
    "#print(myenv.python.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If one needs to add packages\n",
    "#for pip_package in [\"scikit-learn\"]:\n",
    "#    env.python.conda_dependencies.add_pip_package(pip_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference_config = InferenceConfig(entry_script=\"score.py\",\n",
    "#                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
    "#                                                       memory_gb = 1,\n",
    "#                                                      enable_app_insights=True)\n",
    "\n",
    "#service = Model.deploy(\n",
    "#    workspace = ws, \n",
    "#    name = 'titanic_service', \n",
    "#    models = [model], \n",
    "#    inference_config = inference_config, \n",
    "#    deployment_config = deployment_config)\n",
    "\n",
    "#service.wait_for_deployment(True)\n",
    "\n",
    "#print(service.state)\n",
    "#print(\"scoring URI: \" + service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-791556fc6b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Make the request and display the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest_endpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauth_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "scoring_uri = ''\n",
    "key = ''\n",
    "\n",
    "# Two sets of data to score, so we get two results back\n",
    "data = {\"data\":\n",
    "        [\n",
    "          {\n",
    "            \"PassengerId\": 1709,\n",
    "            \"Pclass\": 1,\n",
    "            \"Sex\": 0,\n",
    "            \"SibSp\": 1,\n",
    "            \"Parch\": 0,\n",
    "            \"Fare\": 36.05,\n",
    "            \"FamilySize\": 1,\n",
    "            \"IsAlone\": 0,\n",
    "            \"y\": 0\n",
    "          },\n",
    "          {\n",
    "            \"PassengerId\": 1807,\n",
    "            \"Pclass\": 3,\n",
    "            \"Sex\":1,\n",
    "            \"SibSp\":0,\n",
    "            \"Parch\":0,\n",
    "            \"Fare\": 72.08,\n",
    "            \"FamilySize\": 1,\n",
    "            \"IsAlone\":1,\n",
    "            \"y\":1\n",
    "          }\n",
    "      ]\n",
    "    }\n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "with open(\"data.json\", \"w\") as _f:\n",
    "    _f.write(input_data)\n",
    "    \n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: WebserviceNotFound: Webservice with name Titanic_survival not found in provided workspace\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"WebserviceNotFound: Webservice with name Titanic_survival not found in provided workspace\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2a75f84f71a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# load existing web service\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# enable application insight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, workspace, name)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 raise WebserviceException('WebserviceNotFound: Webservice with name {} not found in provided '\n\u001b[0;32m--> 215\u001b[0;31m                                           'workspace'.format(name))\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWebservice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: WebserviceNotFound: Webservice with name Titanic_survival not found in provided workspace\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"WebserviceNotFound: Webservice with name Titanic_survival not found in provided workspace\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "# standout suggestion\n",
    "logs = service.get_logs()\n",
    "\n",
    "for line in logs.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete service\n",
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standout action: create and publish pipeline\n",
    "ds = ws.get_default_datastore()\n",
    "metrics_output_name = 'metrics_output'\n",
    "best_model_output_name = 'best_model_output'\n",
    "\n",
    "metrics_data = PipelineData(name='metrics_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=metrics_output_name,\n",
    "                           training_output=TrainingOutput(type='Metrics'))\n",
    "model_data = PipelineData(name='model_data',\n",
    "                           datastore=ds,\n",
    "                           pipeline_output_name=best_model_output_name,\n",
    "                           training_output=TrainingOutput(type='Model'))\n",
    "\n",
    "automl_step = AutoMLStep(\n",
    "    name='automl_module',\n",
    "    automl_config=automl_config,\n",
    "    outputs=[metrics_data, model_data],\n",
    "    allow_reuse=True)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    description=\"pipeline_with_automlstep\",\n",
    "    workspace=ws,    \n",
    "    steps=[automl_step])\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(pipeline_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model\n",
    "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
    "num_file_downloaded = best_model_output.download('.', show_progress=True)\n",
    "\n",
    "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
    "    best_model = pickle.load(f)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"Titanic_survival\", description=\"Titanic Survival pipeline\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"pipeline-rest-endpoint\"}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response.raise_for_status()\n",
    "except Exception:    \n",
    "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
    "                    \"Response Code: {}\\n\"\n",
    "                    \"Headers: {}\\n\"\n",
    "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
    "\n",
    "run_id = response.json().get('Id')\n",
    "print('Submitted pipeline run: ', run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline_run = PipelineRun(ws.experiments[\"pipeline-rest-endpoint\"], run_id)\n",
    "RunDetails(published_pipeline_run).show()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
